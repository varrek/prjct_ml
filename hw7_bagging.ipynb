{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UMms33J4jeDZ"
   },
   "source": [
    "1. Use any binary classification dataset\n",
    "2. Define validation strategy and use it for all next steps without changes\n",
    "3. Train decision tree model and estimate performance on validation\n",
    "4. Train bagging model with decision tree as a base model and estimate performance on validation\n",
    "5. Write your own bagging implementation:\n",
    "  <br>5.1. Define init for our CustomBaggingClassifier\n",
    "  <br>5.2. Write fit as described in lecture: divide train data on n parts (`n_estimators` in CustomBaggingClassifier), train `base_estimator` on each part and save these models inside class\n",
    "  <br>5.3. For predictions we should use all saved models and combine their predictions (as voting)\n",
    "6. Compare performance of sklearn bagging model with your own implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas_profiling import ProfileReport\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data/titanic_train.csv')\n",
    "data.drop(columns=['Name', 'Fare', 'PassengerId', 'Cabin', 'Ticket', 'Embarked'], axis = 1, inplace=True)\n",
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['onehotencoder__Sex_female', 'onehotencoder__Sex_male',\n",
       "       'standardscaler__Age', 'standardscaler__SibSp',\n",
       "       'standardscaler__Parch', 'remainder__Pclass'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_features = ['Sex',]\n",
    "numerical_features = ['Age', 'SibSp', 'Parch']\n",
    "ct = make_column_transformer(\n",
    "        (OneHotEncoder(), categorical_features),\n",
    "        (StandardScaler(), numerical_features),\n",
    "        remainder='passthrough', verbose_feature_names_out=True)\n",
    "data_transformed = ct.fit_transform(data.iloc[:, 1:], y=data.Survived)\n",
    "ct.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.530377</td>\n",
       "      <td>0.524570</td>\n",
       "      <td>-0.505895</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.571831</td>\n",
       "      <td>0.524570</td>\n",
       "      <td>-0.505895</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.254825</td>\n",
       "      <td>-0.551703</td>\n",
       "      <td>-0.505895</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.365167</td>\n",
       "      <td>0.524570</td>\n",
       "      <td>-0.505895</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.365167</td>\n",
       "      <td>-0.551703</td>\n",
       "      <td>-0.505895</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.640719</td>\n",
       "      <td>-0.551703</td>\n",
       "      <td>5.357890</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.185937</td>\n",
       "      <td>-0.551703</td>\n",
       "      <td>-0.505895</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.737041</td>\n",
       "      <td>-0.551703</td>\n",
       "      <td>-0.505895</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.254825</td>\n",
       "      <td>-0.551703</td>\n",
       "      <td>-0.505895</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.158503</td>\n",
       "      <td>-0.551703</td>\n",
       "      <td>-0.505895</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>714 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived  Pclass       Sex       Age     SibSp  Parch\n",
       "0         0.0     1.0 -0.530377  0.524570 -0.505895    3.0\n",
       "1         1.0     0.0  0.571831  0.524570 -0.505895    1.0\n",
       "2         1.0     0.0 -0.254825 -0.551703 -0.505895    3.0\n",
       "3         1.0     0.0  0.365167  0.524570 -0.505895    1.0\n",
       "4         0.0     1.0  0.365167 -0.551703 -0.505895    3.0\n",
       "..        ...     ...       ...       ...       ...    ...\n",
       "885       1.0     0.0  0.640719 -0.551703  5.357890    3.0\n",
       "886       0.0     1.0 -0.185937 -0.551703 -0.505895    2.0\n",
       "887       1.0     0.0 -0.737041 -0.551703 -0.505895    1.0\n",
       "889       0.0     1.0 -0.254825 -0.551703 -0.505895    1.0\n",
       "890       0.0     1.0  0.158503 -0.551703 -0.505895    3.0\n",
       "\n",
       "[714 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapper = DataFrameMapper([(data.columns, ct)])\n",
    "scaled_features_df = pd.DataFrame(data_transformed, index=data.index, columns=data.columns)\n",
    "scaled_features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data.Survived)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8665278180237612\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    \"max_features\": [0.7, 0.8, 0.9], \n",
    "    \"max_samples\": [0.7, 0.8, 0.9], \n",
    "    \"base_estimator__max_depth\": range(1, 5, 1),\n",
    "    \"base_estimator__min_samples_leaf\": range(2, 10, 1),\n",
    "    \"base_estimator__min_samples_split\":  range(2, 10, 1),\n",
    "}\n",
    "skf = StratifiedKFold(shuffle=True, random_state=42)\n",
    "bg = BaggingClassifier(DecisionTreeClassifier(), random_state=42, n_estimators=25)\n",
    "r_grid_search = RandomizedSearchCV(bg, param_grid, scoring ='roc_auc', n_iter=20, cv=skf, random_state=42, n_jobs=10)\n",
    "r_grid_search = r_grid_search.fit(scaled_features_df, data.Survived)\n",
    "print(r_grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=DecisionTreeClassifier(max_depth=3,\n",
       "                                                        min_samples_leaf=3,\n",
       "                                                        min_samples_split=3),\n",
       "                  max_features=0.8, max_samples=0.9, n_estimators=25,\n",
       "                  random_state=42)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('columntransformer',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('onehotencoder',\n",
       "                                                  OneHotEncoder(), ['Sex']),\n",
       "                                                 ('standardscaler',\n",
       "                                                  StandardScaler(),\n",
       "                                                  ['Age', 'SibSp', 'Parch'])])),\n",
       "                ('baggingclassifier',\n",
       "                 BaggingClassifier(base_estimator=DecisionTreeClassifier(max_depth=3,\n",
       "                                                                         min_samples_leaf=3,\n",
       "                                                                         min_samples_split=3),\n",
       "                                   max_features=0.8, max_samples=0.9,\n",
       "                                   n_estimators=25, random_state=42))])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_transformed = ct.fit_transform(data.iloc[:, 1:])\n",
    "bagging = BaggingClassifier(base_estimator=DecisionTreeClassifier(max_depth=3,\n",
    "                                                        min_samples_leaf=3,\n",
    "                                                        min_samples_split=3),\n",
    "                  max_features=0.8, max_samples=0.9, n_estimators=25,\n",
    "                  random_state=42)\n",
    "model = make_pipeline(ct, bagging)\n",
    "model.fit(data.iloc[:, 1:], data.Survived)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('./data/titanic_test.csv')\n",
    "age_avg = test['Age'].mean()\n",
    "test[['Age']] = test[['Age']].fillna(age_avg)\n",
    "PassengerId = test['PassengerId']\n",
    "y_pred = model.predict(test[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch']])\n",
    "submission = pd.DataFrame({\n",
    "        \"PassengerId\": PassengerId,\n",
    "        \"Survived\": y_pred\n",
    "    })\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "ZSixk8wXjZJZ"
   },
   "outputs": [],
   "source": [
    "class CustomBaggingClassifier:\n",
    "    def __init__(self, base_estimator, n_estimators, max_samples, max_features, max_depth):\n",
    "        self.base_estimator = base_estimator\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_samples = max_samples\n",
    "        self.max_features = max_features\n",
    "        self.max_depth = max_depth\n",
    "        self.models = []\n",
    "  \n",
    "    def fit(self, X, y):\n",
    "        for estimator in range(self.n_estimators):\n",
    "            \n",
    "            sample = np.random.choice(np.arange(self.max_samples), size = self.max_samples, replace = True)\n",
    "            X_train_b = X[sample]\n",
    "            y_train_b = y[sample]\n",
    "            \n",
    "            model = self.base_estimator\n",
    "            model.fit(X_train_b, y_train_b)\n",
    "            self.models.append(model)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        y_test_hats = np.empty((len(self.models), len(X)))\n",
    "        for i, model in enumerate(self.models):\n",
    "            y_test_hats[i] = model.predict(X)\n",
    "        \n",
    "        return y_test_hats.mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "bagger = CustomBaggingClassifier(DecisionTreeClassifier(), 25, 5, 10, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "bagger.fit(data_transformed, data.Survived)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = ['Sex',]\n",
    "numerical_features = ['Age', 'SibSp', 'Parch', 'Pclass']\n",
    "ct = make_column_transformer(\n",
    "        (OneHotEncoder(), categorical_features),\n",
    "        (StandardScaler(), numerical_features),\n",
    "        remainder='drop', verbose_feature_names_out=True)\n",
    "test_transformed = ct.fit_transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_hat = bagger.predict(test_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0.,\n",
       "       0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 1.,\n",
       "       0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0.,\n",
       "       0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0.,\n",
       "       0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0.,\n",
       "       0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0.,\n",
       "       1., 1., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "       0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "       1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1.,\n",
       "       0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1.,\n",
       "       0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1.,\n",
       "       0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1.,\n",
       "       0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "       1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "       1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
       "       0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 0., 0., 1., 0., 1.,\n",
       "       0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0.,\n",
       "       1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       1., 1., 1., 1., 1., 0., 1., 0., 0., 0.])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "        \"PassengerId\": PassengerId,\n",
    "        \"Survived\": y_test_hat.astype(int)\n",
    "    })\n",
    "submission.to_csv('submission_custom.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Bagging homework.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
